auth_key_user: ubuntu

head_nodes: "{{ groups['galaxy_slurm_head'] }}"
worker_nodes: "{{ groups['galaxy_workers'] }}"
galaxy_nodes: "{{ groups['galaxy_galaxy_server'] }}"

add_galaxy_user: true # Adds the galaxy user to all machines that have slurm on them

# SLURM
slurm_nodes:
  - name: galaxy-w1
    NodeAddr: "{{ hostvars['galaxy-w1']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    Weight: 20
    State: UNKNOWN
  - name: galaxy-w2
    NodeAddr: "{{ hostvars['galaxy-w2']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    Weight: 30
    State: UNKNOWN
  - name: galaxy-w3
    NodeAddr: "{{ hostvars['galaxy-w3']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    Weight: 4  # usually 40, set low while w3 is training only
    State: UNKNOWN
  - name: galaxy-w4
    NodeAddr: "{{ hostvars['galaxy-w4']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    Weight: 50
    State: UNKNOWN
  - name: galaxy-w5
    NodeAddr: "{{ hostvars['galaxy-w5']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    Weight: 60
    State: UNKNOWN
  - name: galaxy-w6
    NodeAddr: "{{ hostvars['galaxy-w6']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    Weight: 70
    State: UNKNOWN
  - name: galaxy-w7
    NodeAddr: "{{ hostvars['galaxy-w7']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    Weight: 10
    State: UNKNOWN
  - name: galaxy-w8
    NodeAddr: "{{ hostvars['galaxy-w8']['internal_ip'] }}"
    CPUs: 32
    RealMemory: 128000
    Weight: 110
    State: UNKNOWN
  - name: galaxy-w9
    NodeAddr: "{{ hostvars['galaxy-w9']['internal_ip'] }}"
    CPUs: 32
    RealMemory: 128000
    Weight: 120
    State: UNKNOWN
  - name: galaxy-w10
    NodeAddr: "{{ hostvars['galaxy-w10']['internal_ip'] }}"
    CPUs: 32
    RealMemory: 128000
    Weight: 130
    State: UNKNOWN
  - name: galaxy-queue
    NodeAddr: "{{ hostvars['galaxy-queue']['internal_ip'] }}"
    CPUs: 4
    RealMemory: 15638
    State: UNKNOWN
  - name: galaxy
    NodeAddr: "{{ hostvars['galaxy']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    State: UNKNOWN
  ##& Include galaxy-handlers in slurm config for 2-VM galaxy server. Comment out when using a single VM for galaxy server
  - name: galaxy-handlers
    NodeAddr:  "{{ hostvars['galaxy-handlers']['internal_ip'] }}"
    CPUs: 16
    RealMemory: 64000
    State: UNKNOWN


slurm_partitions:
  - name: main
    # nodes: "galaxy-w1,galaxy-w2,galaxy-w3,galaxy-w4,galaxy-w5,galaxy-w6,galaxy-w8,galaxy-w9,galaxy-w10"
    nodes: "galaxy-w1,galaxy-w2,galaxy-w4,galaxy-w5,galaxy-w6,galaxy-w8,galaxy-w9,galaxy-w10"  #  exclude w3 for SBL training
    Default: YES
    State: UP
  - name: training
    nodes: "galaxy-w7,galaxy-w1,galaxy-w2,galaxy-w3,galaxy-w4,galaxy-w5,galaxy-w6,galaxy-w8,galaxy-w9,galaxy-w10"
    Default: NO
    State: UP
  - name: interactive_tools
    nodes: "galaxy-w4,galaxy-w5,galaxy-w6"
    Default: NO
    State: UP
    MaxTime: "10:00:00"
  - name: msconvert  # these are the slurm workers that will generate .wine folders with the correct permissions (700) for msconvert version 3.0.20287.2
    nodes: "galaxy-w1,galaxy-w2,galaxy-w3,galaxy-w8"
    Default: NO
    State: UP

slurm_controller_host: galaxy-queue

slurm_munge_key: files/keys/munge.key
